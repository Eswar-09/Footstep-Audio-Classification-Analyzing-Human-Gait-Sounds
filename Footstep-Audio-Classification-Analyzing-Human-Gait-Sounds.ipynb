{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a58d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as ps \n",
    "import os \n",
    "import IPython.display as ipd \n",
    "import pandas as pd\n",
    "import librosa\n",
    "#import librosa.display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f102d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>classID</th>\n",
       "      <th>Numeric ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-054_...</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-055_...</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-056_...</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-057_...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-058_...</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       relative_path  classID  Numeric ID\n",
       "0  C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-054_...        1          54\n",
       "1  C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-055_...        1          55\n",
       "2  C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-056_...        1          56\n",
       "3  C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-057_...        1          57\n",
       "4  C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-058_...        1          58"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = r\"C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-115_person A.wav\"\n",
    "metadata = pd.read_csv(r\"C:\\Users\\Ruchita Gayatri\\Downloads\\audio_data.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5f5e9457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load audio file\n",
    "librosa_audio_data, librosa_sample_rate = librosa.load(r\"C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-113_person A.wav\")\n",
    "\n",
    "# Generate the time axis\n",
    "duration = len(librosa_audio_data) / librosa_sample_rate\n",
    "time = librosa.times_like(librosa_audio_data, sr=librosa_sample_rate)\n",
    "\n",
    "# Create the waveform plot\n",
    "plt.figure()\n",
    "plt.plot(time, librosa_audio_data, linewidth=0.5)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Waveform')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81838450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio,sample_rate = librosa.load(file_name)\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=100)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855cb9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13a3c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-364.301, 69.396645, 17.120214, 15.068575, 8....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-429.45187, 68.53903, 11.999503, 20.091782, 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-383.5, 47.17122, 22.387608, 19.533028, 10.05...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-368.046, 82.30127, 6.60783, 15.252235, 2.379...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-370.9838, 71.60263, 16.738106, 16.171688, 5....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [-364.301, 69.396645, 17.120214, 15.068575, 8....      1\n",
       "1  [-429.45187, 68.53903, 11.999503, 20.091782, 6...      1\n",
       "2  [-383.5, 47.17122, 22.387608, 19.533028, 10.05...      1\n",
       "3  [-368.046, 82.30127, 6.60783, 15.252235, 2.379...      1\n",
       "4  [-370.9838, 71.60263, 16.738106, 16.171688, 5....      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Extraction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "extracted_features = []\n",
    "for i in range(51):\n",
    "    file_name = metadata.loc[i, 'relative_path']\n",
    "    #file_name = f'r\"{file_name1}\"'\n",
    "    final_class_labels = metadata.loc[i, 'classID']\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])\n",
    "\n",
    "extracted_features_df = pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c10056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into independent and dependent dataset\n",
    "X = np.array(extracted_features_df['feature'].tolist())\n",
    "y = np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b69ded0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ff2034a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cb55daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for ML model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ccbdabf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruchita Gayatri\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy: 1.0\n",
      "DecisionTreeClassifier accuracy: 0.8571428571428571\n",
      "RandomForestClassifier accuracy: 1.0\n",
      "SVC accuracy: 0.47619047619047616\n",
      "KNeighborsClassifier accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning Model \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(model.__class__.__name__, \"accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f1c2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DL-Model\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64e73298",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2  # Class labels (Person-A,Person-B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "302de667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "## 1st layer \n",
    "model.add(Dense(200,input_shape=(100,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## 2nd layer \n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## 3rd layer \n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## final layer \n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a59ce46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,702\n",
      "Trainable params: 80,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "efa7bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eca1320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split for DL\n",
    "\n",
    "y1 = np.array(pd.get_dummies(y)) # Categorical variables to One hot encoder for DL\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y1,test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a2979533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.1334 - accuracy: 0.5000\n",
      "Epoch 1: val_loss improved from inf to 2.78983, saving model to Downloads\\audio_classification.hdf5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.1334 - accuracy: 0.5000 - val_loss: 2.7898 - val_accuracy: 0.4762\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.9694 - accuracy: 0.6000\n",
      "Epoch 2: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 21.9694 - accuracy: 0.6000 - val_loss: 9.1604 - val_accuracy: 0.4762\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.0735 - accuracy: 0.6000\n",
      "Epoch 3: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.0735 - accuracy: 0.6000 - val_loss: 12.8063 - val_accuracy: 0.4762\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 28.2709 - accuracy: 0.5000\n",
      "Epoch 4: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 28.2709 - accuracy: 0.5000 - val_loss: 14.5970 - val_accuracy: 0.4762\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 21.6826 - accuracy: 0.4333\n",
      "Epoch 5: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 21.6826 - accuracy: 0.4333 - val_loss: 13.8910 - val_accuracy: 0.4762\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 22.6364 - accuracy: 0.5333\n",
      "Epoch 6: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 22.6364 - accuracy: 0.5333 - val_loss: 13.0523 - val_accuracy: 0.4762\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 20.9066 - accuracy: 0.5000\n",
      "Epoch 7: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 20.9066 - accuracy: 0.5000 - val_loss: 11.2129 - val_accuracy: 0.4762\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.5748 - accuracy: 0.5333\n",
      "Epoch 8: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 12.5748 - accuracy: 0.5333 - val_loss: 8.9121 - val_accuracy: 0.4762\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.8904 - accuracy: 0.5333\n",
      "Epoch 9: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.8904 - accuracy: 0.5333 - val_loss: 6.6333 - val_accuracy: 0.4762\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.4839 - accuracy: 0.5667\n",
      "Epoch 10: val_loss did not improve from 2.78983\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 11.4839 - accuracy: 0.5667 - val_loss: 4.5991 - val_accuracy: 0.4762\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0325 - accuracy: 0.5333\n",
      "Epoch 11: val_loss improved from 2.78983 to 2.40555, saving model to Downloads\\audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 10.0325 - accuracy: 0.5333 - val_loss: 2.4055 - val_accuracy: 0.4762\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.5473 - accuracy: 0.6333\n",
      "Epoch 12: val_loss improved from 2.40555 to 0.53456, saving model to Downloads\\audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 10.5473 - accuracy: 0.6333 - val_loss: 0.5346 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.9961 - accuracy: 0.3667\n",
      "Epoch 13: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 18.9961 - accuracy: 0.3667 - val_loss: 0.7640 - val_accuracy: 0.5238\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 16.6690 - accuracy: 0.5333\n",
      "Epoch 14: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 16.6690 - accuracy: 0.5333 - val_loss: 1.6283 - val_accuracy: 0.5238\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6121 - accuracy: 0.5667\n",
      "Epoch 15: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 11.6121 - accuracy: 0.5667 - val_loss: 2.1629 - val_accuracy: 0.5238\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.1675 - accuracy: 0.6333\n",
      "Epoch 16: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 11.1675 - accuracy: 0.6333 - val_loss: 2.2274 - val_accuracy: 0.5238\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3772 - accuracy: 0.6000\n",
      "Epoch 17: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 12.3772 - accuracy: 0.6000 - val_loss: 2.1567 - val_accuracy: 0.5238\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.2204 - accuracy: 0.5000\n",
      "Epoch 18: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 18.2204 - accuracy: 0.5000 - val_loss: 2.2867 - val_accuracy: 0.5238\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0937 - accuracy: 0.6333\n",
      "Epoch 19: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 9.0937 - accuracy: 0.6333 - val_loss: 2.2971 - val_accuracy: 0.5238\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 18.0170 - accuracy: 0.3667\n",
      "Epoch 20: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 18.0170 - accuracy: 0.3667 - val_loss: 2.0958 - val_accuracy: 0.5238\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.1041 - accuracy: 0.5333\n",
      "Epoch 21: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 11.1041 - accuracy: 0.5333 - val_loss: 1.9962 - val_accuracy: 0.5238\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.2853 - accuracy: 0.4000\n",
      "Epoch 22: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 13.2853 - accuracy: 0.4000 - val_loss: 1.7866 - val_accuracy: 0.5238\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.3992 - accuracy: 0.4333\n",
      "Epoch 23: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 13.3992 - accuracy: 0.4333 - val_loss: 1.6557 - val_accuracy: 0.5238\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.5227 - accuracy: 0.3667\n",
      "Epoch 24: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 12.5227 - accuracy: 0.3667 - val_loss: 1.5723 - val_accuracy: 0.5238\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8648 - accuracy: 0.5333\n",
      "Epoch 25: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10.8648 - accuracy: 0.5333 - val_loss: 1.6642 - val_accuracy: 0.5238\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7956 - accuracy: 0.6667\n",
      "Epoch 26: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7956 - accuracy: 0.6667 - val_loss: 1.6823 - val_accuracy: 0.5238\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.0941 - accuracy: 0.4333\n",
      "Epoch 27: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12.0941 - accuracy: 0.4333 - val_loss: 1.5624 - val_accuracy: 0.5238\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6607 - accuracy: 0.7000\n",
      "Epoch 28: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.6607 - accuracy: 0.7000 - val_loss: 1.4896 - val_accuracy: 0.5238\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3687 - accuracy: 0.4667\n",
      "Epoch 29: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.3687 - accuracy: 0.4667 - val_loss: 1.5178 - val_accuracy: 0.5238\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.1461 - accuracy: 0.5000\n",
      "Epoch 30: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 11.1461 - accuracy: 0.5000 - val_loss: 1.5117 - val_accuracy: 0.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5094 - accuracy: 0.6333\n",
      "Epoch 31: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 9.5094 - accuracy: 0.6333 - val_loss: 1.3868 - val_accuracy: 0.5238\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.2994 - accuracy: 0.3333\n",
      "Epoch 32: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10.2994 - accuracy: 0.3333 - val_loss: 1.1492 - val_accuracy: 0.5238\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5141 - accuracy: 0.5333\n",
      "Epoch 33: val_loss did not improve from 0.53456\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.5141 - accuracy: 0.5333 - val_loss: 0.7470 - val_accuracy: 0.5238\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0851 - accuracy: 0.5000\n",
      "Epoch 34: val_loss improved from 0.53456 to 0.52482, saving model to Downloads\\audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 10.0851 - accuracy: 0.5000 - val_loss: 0.5248 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3160 - accuracy: 0.6000\n",
      "Epoch 35: val_loss improved from 0.52482 to 0.45834, saving model to Downloads\\audio_classification.hdf5\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 8.3160 - accuracy: 0.6000 - val_loss: 0.4583 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4075 - accuracy: 0.5000\n",
      "Epoch 36: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.4075 - accuracy: 0.5000 - val_loss: 0.4648 - val_accuracy: 0.8095\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2677 - accuracy: 0.5333\n",
      "Epoch 37: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 7.2677 - accuracy: 0.5333 - val_loss: 0.4826 - val_accuracy: 0.7619\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.8806 - accuracy: 0.5667\n",
      "Epoch 38: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 8.8806 - accuracy: 0.5667 - val_loss: 0.5147 - val_accuracy: 0.6190\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.1084 - accuracy: 0.5333\n",
      "Epoch 39: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.1084 - accuracy: 0.5333 - val_loss: 0.5679 - val_accuracy: 0.5238\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8302 - accuracy: 0.4333\n",
      "Epoch 40: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 10.8302 - accuracy: 0.4333 - val_loss: 0.5740 - val_accuracy: 0.5238\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3371 - accuracy: 0.6000\n",
      "Epoch 41: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 6.3371 - accuracy: 0.6000 - val_loss: 0.5608 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.7334 - accuracy: 0.3000\n",
      "Epoch 42: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 12.7334 - accuracy: 0.3000 - val_loss: 0.5520 - val_accuracy: 0.6190\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1369 - accuracy: 0.6333\n",
      "Epoch 43: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.1369 - accuracy: 0.6333 - val_loss: 0.5581 - val_accuracy: 0.6190\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7201 - accuracy: 0.5667\n",
      "Epoch 44: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.7201 - accuracy: 0.5667 - val_loss: 0.5639 - val_accuracy: 0.6190\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7187 - accuracy: 0.5667\n",
      "Epoch 45: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.7187 - accuracy: 0.5667 - val_loss: 0.5776 - val_accuracy: 0.5238\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8458 - accuracy: 0.6333\n",
      "Epoch 46: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 6.8458 - accuracy: 0.6333 - val_loss: 0.5839 - val_accuracy: 0.5238\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1524 - accuracy: 0.6667\n",
      "Epoch 47: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1524 - accuracy: 0.6667 - val_loss: 0.5873 - val_accuracy: 0.5238\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.7422 - accuracy: 0.3667\n",
      "Epoch 48: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.7422 - accuracy: 0.3667 - val_loss: 0.6135 - val_accuracy: 0.5238\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9255 - accuracy: 0.4667\n",
      "Epoch 49: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.9255 - accuracy: 0.4667 - val_loss: 0.6176 - val_accuracy: 0.5238\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2532 - accuracy: 0.5000\n",
      "Epoch 50: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.2532 - accuracy: 0.5000 - val_loss: 0.6193 - val_accuracy: 0.5238\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9904 - accuracy: 0.6667\n",
      "Epoch 51: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.9904 - accuracy: 0.6667 - val_loss: 0.6382 - val_accuracy: 0.5238\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8400 - accuracy: 0.5667\n",
      "Epoch 52: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.8400 - accuracy: 0.5667 - val_loss: 0.6644 - val_accuracy: 0.5238\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.5563 - accuracy: 0.5000\n",
      "Epoch 53: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10.5563 - accuracy: 0.5000 - val_loss: 0.6953 - val_accuracy: 0.5238\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8244 - accuracy: 0.4333\n",
      "Epoch 54: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.8244 - accuracy: 0.4333 - val_loss: 0.7166 - val_accuracy: 0.5238\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7156 - accuracy: 0.5333\n",
      "Epoch 55: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.7156 - accuracy: 0.5333 - val_loss: 0.7367 - val_accuracy: 0.5238\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4785 - accuracy: 0.6333\n",
      "Epoch 56: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.4785 - accuracy: 0.6333 - val_loss: 0.7518 - val_accuracy: 0.5238\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3486 - accuracy: 0.4000\n",
      "Epoch 57: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 7.3486 - accuracy: 0.4000 - val_loss: 0.7629 - val_accuracy: 0.5238\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0453 - accuracy: 0.4000\n",
      "Epoch 58: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 9.0453 - accuracy: 0.4000 - val_loss: 0.8050 - val_accuracy: 0.5238\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9640 - accuracy: 0.5667\n",
      "Epoch 59: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.9640 - accuracy: 0.5667 - val_loss: 0.8401 - val_accuracy: 0.5238\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1848 - accuracy: 0.6000\n",
      "Epoch 60: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.1848 - accuracy: 0.6000 - val_loss: 0.8550 - val_accuracy: 0.5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9547 - accuracy: 0.5333\n",
      "Epoch 61: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.9547 - accuracy: 0.5333 - val_loss: 0.8568 - val_accuracy: 0.5238\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8896 - accuracy: 0.5333\n",
      "Epoch 62: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.8896 - accuracy: 0.5333 - val_loss: 0.8537 - val_accuracy: 0.5238\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4151 - accuracy: 0.5000\n",
      "Epoch 63: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.4151 - accuracy: 0.5000 - val_loss: 0.8367 - val_accuracy: 0.5238\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8358 - accuracy: 0.4667\n",
      "Epoch 64: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 4.8358 - accuracy: 0.4667 - val_loss: 0.8198 - val_accuracy: 0.5238\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3357 - accuracy: 0.6333\n",
      "Epoch 65: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.3357 - accuracy: 0.6333 - val_loss: 0.7867 - val_accuracy: 0.5238\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4747 - accuracy: 0.5667\n",
      "Epoch 66: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.4747 - accuracy: 0.5667 - val_loss: 0.7335 - val_accuracy: 0.5238\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1931 - accuracy: 0.5667\n",
      "Epoch 67: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.1931 - accuracy: 0.5667 - val_loss: 0.6745 - val_accuracy: 0.5238\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5879 - accuracy: 0.5333\n",
      "Epoch 68: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.5879 - accuracy: 0.5333 - val_loss: 0.6275 - val_accuracy: 0.5238\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0061 - accuracy: 0.6333\n",
      "Epoch 69: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.0061 - accuracy: 0.6333 - val_loss: 0.5893 - val_accuracy: 0.5238\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7736 - accuracy: 0.5000\n",
      "Epoch 70: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.7736 - accuracy: 0.5000 - val_loss: 0.5668 - val_accuracy: 0.5238\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1346 - accuracy: 0.5333\n",
      "Epoch 71: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.1346 - accuracy: 0.5333 - val_loss: 0.5595 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2070 - accuracy: 0.4667\n",
      "Epoch 72: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.2070 - accuracy: 0.4667 - val_loss: 0.5618 - val_accuracy: 0.9048\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8960 - accuracy: 0.5000\n",
      "Epoch 73: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.8960 - accuracy: 0.5000 - val_loss: 0.5687 - val_accuracy: 0.9524\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5892 - accuracy: 0.5000\n",
      "Epoch 74: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.5892 - accuracy: 0.5000 - val_loss: 0.5793 - val_accuracy: 0.9048\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8653 - accuracy: 0.4667\n",
      "Epoch 75: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.8653 - accuracy: 0.4667 - val_loss: 0.5843 - val_accuracy: 0.9048\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1841 - accuracy: 0.5000\n",
      "Epoch 76: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.1841 - accuracy: 0.5000 - val_loss: 0.5859 - val_accuracy: 0.9048\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3664 - accuracy: 0.5000\n",
      "Epoch 77: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.3664 - accuracy: 0.5000 - val_loss: 0.5876 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4055 - accuracy: 0.5000\n",
      "Epoch 78: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.4055 - accuracy: 0.5000 - val_loss: 0.5862 - val_accuracy: 0.9048\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1826 - accuracy: 0.4333\n",
      "Epoch 79: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.1826 - accuracy: 0.4333 - val_loss: 0.5844 - val_accuracy: 0.9524\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8895 - accuracy: 0.5000\n",
      "Epoch 80: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.8895 - accuracy: 0.5000 - val_loss: 0.5822 - val_accuracy: 0.9048\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1395 - accuracy: 0.5333\n",
      "Epoch 81: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.1395 - accuracy: 0.5333 - val_loss: 0.5686 - val_accuracy: 0.9048\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0644 - accuracy: 0.5000\n",
      "Epoch 82: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 4.0644 - accuracy: 0.5000 - val_loss: 0.5524 - val_accuracy: 0.9048\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0003 - accuracy: 0.5667\n",
      "Epoch 83: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.0003 - accuracy: 0.5667 - val_loss: 0.5409 - val_accuracy: 0.9048\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9803 - accuracy: 0.5667\n",
      "Epoch 84: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.9803 - accuracy: 0.5667 - val_loss: 0.5340 - val_accuracy: 0.9048\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4676 - accuracy: 0.5667\n",
      "Epoch 85: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.4676 - accuracy: 0.5667 - val_loss: 0.5330 - val_accuracy: 0.9048\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7042 - accuracy: 0.5000\n",
      "Epoch 86: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.7042 - accuracy: 0.5000 - val_loss: 0.5335 - val_accuracy: 0.9048\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7902 - accuracy: 0.6000\n",
      "Epoch 87: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7902 - accuracy: 0.6000 - val_loss: 0.5383 - val_accuracy: 0.7619\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5911 - accuracy: 0.5667\n",
      "Epoch 88: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.5911 - accuracy: 0.5667 - val_loss: 0.5459 - val_accuracy: 0.7143\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.6333\n",
      "Epoch 89: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5055 - accuracy: 0.6333 - val_loss: 0.5516 - val_accuracy: 0.5714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3554 - accuracy: 0.6000\n",
      "Epoch 90: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.3554 - accuracy: 0.6000 - val_loss: 0.5551 - val_accuracy: 0.5714\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 3.3910 - accuracy: 0.4333\n",
      "Epoch 91: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.3910 - accuracy: 0.4333 - val_loss: 0.5542 - val_accuracy: 0.5714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7709 - accuracy: 0.5667\n",
      "Epoch 92: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.7709 - accuracy: 0.5667 - val_loss: 0.5523 - val_accuracy: 0.5714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0551 - accuracy: 0.5667\n",
      "Epoch 93: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0551 - accuracy: 0.5667 - val_loss: 0.5469 - val_accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5261 - accuracy: 0.6333\n",
      "Epoch 94: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.5261 - accuracy: 0.6333 - val_loss: 0.5389 - val_accuracy: 0.7143\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4053 - accuracy: 0.5333\n",
      "Epoch 95: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.4053 - accuracy: 0.5333 - val_loss: 0.5353 - val_accuracy: 0.8571\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7396 - accuracy: 0.5667\n",
      "Epoch 96: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.7396 - accuracy: 0.5667 - val_loss: 0.5338 - val_accuracy: 0.9048\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9000 - accuracy: 0.5333\n",
      "Epoch 97: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.9000 - accuracy: 0.5333 - val_loss: 0.5357 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0714 - accuracy: 0.5000\n",
      "Epoch 98: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.0714 - accuracy: 0.5000 - val_loss: 0.5418 - val_accuracy: 0.9048\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5045 - accuracy: 0.5000\n",
      "Epoch 99: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.5045 - accuracy: 0.5000 - val_loss: 0.5474 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0570 - accuracy: 0.6333\n",
      "Epoch 100: val_loss did not improve from 0.45834\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0570 - accuracy: 0.6333 - val_loss: 0.5512 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124258fb820>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training Model\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100 \n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='Downloads/audio_classification.hdf5',verbose=1,save_best_only=True)\n",
    "\n",
    "model.fit(X_train,y_train,batch_size=num_batch_size,epochs= num_epochs,validation_data=(X_test,y_test),callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ee6a8a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047619104385376\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b6e1ed61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n",
      "Predicted class: Person B\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "\n",
    "file_name = r\"C:\\Users\\Ruchita Gayatri\\Downloads\\AB\\STE-063_person B.wav\"\n",
    "prediction_feature = features_extractor(filename)\n",
    "prediction_feature = prediction_feature.reshape(1, -1)\n",
    "predicted_probabilities = model.predict(prediction_feature)\n",
    "predicted_class = np.argmax(predicted_probabilities)\n",
    "\n",
    "if predicted_class == 1 :\n",
    "    print(\"Predicted class: Person A\")\n",
    "else :\n",
    "     print(\"Predicted class: Person B\")\n",
    "    \n",
    "#print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5b86ef5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9700\\3841014271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Select a random batch of real samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mreal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "### GAN - For artificial data generation \n",
    "dataset = extracted_features_df.values\n",
    "\n",
    "# Separate features and labels\n",
    "features = dataset[0]\n",
    "labels = dataset[1]\n",
    "\n",
    "# Define the GAN architecture\n",
    "latent_dim = 100  # Size of the random noise vector\n",
    "\n",
    "# Generator model\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128, input_dim=latent_dim, activation='relu'))\n",
    "generator.add(Dense(features.shape[0], activation='linear'))  # Output shape matches feature size\n",
    "\n",
    "# Discriminator model\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(128, input_dim=features.shape[0], activation='relu'))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Combined GAN model\n",
    "discriminator.trainable = False  # Freeze discriminator during generator training\n",
    "gan = Sequential([generator, discriminator])\n",
    "\n",
    "# Compile models\n",
    "generator.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
    "discriminator.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
    "gan.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
    "\n",
    "# Train the GAN\n",
    "epochs = 1000\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Select a random batch of real samples\n",
    "    idx = np.random.randint(0, features.shape[1], batch_size)\n",
    "    real_samples = np.transpose(features[:, idx]).astype(np.float32)\n",
    "\n",
    "    # Generate random noise as input to the generator\n",
    "    noise = np.random.randn(batch_size, latent_dim)\n",
    "\n",
    "    # Generate a batch of fake samples\n",
    "    fake_samples = generator.predict(noise)\n",
    "\n",
    "    # Train the discriminator\n",
    "    discriminator.trainable = True\n",
    "    discriminator_loss_real = discriminator.train_on_batch(real_samples, np.ones((batch_size, 1), dtype=np.float32))\n",
    "    discriminator_loss_fake = discriminator.train_on_batch(fake_samples, np.zeros((batch_size, 1), dtype=np.float32))\n",
    "    discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "\n",
    "    # Train the generator\n",
    "    discriminator.trainable = False\n",
    "    generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1), dtype=np.float32))\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | D Loss: {discriminator_loss} | G Loss: {generator_loss}\")\n",
    "\n",
    "# Generate new data using the trained generator\n",
    "num_samples = 10\n",
    "noise = np.random.randn(num_samples, latent_dim)\n",
    "generated_data = generator.predict(noise)\n",
    "\n",
    "# Plot the generated data\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.plot(generated_data[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc78ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
